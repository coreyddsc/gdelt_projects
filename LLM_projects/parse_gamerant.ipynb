{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64184f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import gdelt # for gdelt searchs\n",
    "from gkg_tools import * # for gkg searchs\n",
    "# %run \"../gkg_tools.py\" # using magic command run to access the script from the parent directory\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "import torch\n",
    "\n",
    "# GPU Timing (using GPU 1) else -1 for CPU\n",
    "device_id = 1 if torch.cuda.is_available() else -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61072b35",
   "metadata": {},
   "source": [
    "# Get Article from GDELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dfafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkg = gkg_operator() # create a gkg operator\n",
    "gkg.set_date(['2024 Oct 20', '2024 Oct 21']) # set the date range for the search\n",
    "gkg.get_gkg()\n",
    "persons = ['Eiichiro Oda', 'Shueisha', 'One Piece']\n",
    "OP = gkg.gkg_persons(persons)\n",
    "OP.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0d84b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gamerant.com/one-piece-sun-god-loki-nika-luffy/'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = OP['documentidentifier'].iloc[0] # screen rant using index 1 and 8\n",
    "url\n",
    "\n",
    "# I tried to suppress this warning which occurs when querying from the lambda2 server, didn't work, so I dropped the warning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4503af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    \n",
    "session = requests.Session()\n",
    "retry = Retry(connect=2, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "try:\n",
    "    response = session.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba1e85",
   "metadata": {},
   "source": [
    "## Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6f738a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game Rant',\n",
       " 'One Piece Chapter 1130: Oda Finally Introduces Loki',\n",
       " ' The Straw Hats Continue To Sail It To Elbaf ',\n",
       " ' The Lore About The Land Of The Giants ',\n",
       " ' Luffy Meets Loki in One Piece 1130 ',\n",
       " 'Will Loki Have A Zoan Devil Fruit?',\n",
       " 'Related',\n",
       " 'Key Takeaways',\n",
       " ' The Giants Of Elbaf Had A King Named Harald ',\n",
       " ' Luffy and The Accursed Prince Meet ',\n",
       " 'Trending Now']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = soup.find_all('h1')\n",
    "header_text = []\n",
    "for i in range(1,5):\n",
    "    headers = soup.find_all(f'h{i}')\n",
    "    for h in headers:\n",
    "        header_text.append(h.get_text())\n",
    "    \n",
    "header_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0e649",
   "metadata": {},
   "source": [
    "## Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "00d6ccfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><em><strong>One Piece</strong></em> chapter 1130 is out officially, and fans are thoroughly blown away by what can be described to be one of the best chapters in the entire series. This week's chapter was absolutely stunning from start to finish, <a href=\"https://gamerant.com/one-piece-best-post-timeskip-feat-every-straw-hat/\" target=\"_blank\">as the Straw Hat Pirates finally explored the real Elbaf</a>.</p>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = soup.find_all('p')\n",
    "paragraphs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b4826478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 28\n",
      "1 0 0\n",
      "2 1 13\n",
      "3 1 27\n",
      "4 1 33\n",
      "5 1 58\n",
      "6 1 58\n",
      "7 4 278\n",
      "8 1 119\n",
      "9 1 348\n",
      "10 2 605\n",
      "11 1 50\n",
      "12 3 515\n",
      "13 1 510\n",
      "14 1 738\n",
      "15 3 662\n",
      "16 1 84\n",
      "17 1 516\n",
      "18 1 116\n",
      "19 2 482\n",
      "20 5 542\n",
      "21 3 495\n",
      "22 3 715\n",
      "23 1 247\n",
      "24 0 0\n",
      "25 1 28\n",
      "26 0 0\n",
      "27 1 13\n",
      "28 1 27\n",
      "29 1 33\n",
      "30 1 58\n",
      "31 1 101\n",
      "32 1 31\n",
      "33 0 0\n",
      "34 1 47\n",
      "35 1 108\n",
      "36 1 116\n",
      "37 1 145\n",
      "38 1 145\n",
      "39 1 146\n",
      "40 1 134\n",
      "41 1 138\n",
      "Number of Paragraphs:42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Please verify your email address.',\n",
       " 'Youâ€™ve reached your account maximum for followed topics.',\n",
       " \"This article contains spoilers from One Piece's Elbaf Arc.\",\n",
       " \"One Piece chapter 1130 is out officially, and fans are thoroughly blown away by what can be described to be one of the best chapters in the entire series. This week's chapter was absolutely stunning from start to finish, as the Straw Hat Pirates finally explored the real Elbaf.\",\n",
       " \"One Piece fans should be excited about Oda's two major projects during the manga break. Here's what to look forward to.\",\n",
       " \"Quite a lot of interesting things, such as the lore about Elbaf and its former King, were revealed in this chapter, and at the same time, the character that fans were anticipating to see the most in this arc, Loki, made his appearance as well. Finally, things are underway in this arc of majestic proportions, and it can't get any better than this.\",\n",
       " 'One Piece chapter 1130 saw the Straw Hat Pirates finally break out of Rodoâ€™s prison. As fans saw in the previous chapter, Luffy did not waste even a single second to break out of the detention center, and now, the crew found themselves in the real Elbaf. In this land, fans got to see a giant castle, which, as was said previously, was actually a giant detention center. Along the giant Castle was a massive bridge that connected to a level on top. It appears that Elbaf is leveled, and of course, more about this was revealed later down the line, when the full design of this place was revealed by Oda.',\n",
       " \"Let's call off the search for the crew! â€“ Franky\",\n",
       " 'While Elbaf looks huge, fans only got to see the crew traverse through the snowy region and then attempt to climb the bridge that connects to a higher level. Before that, two members of the New Giant Warrior Pirates, whom the fans have seen previously in the story, known as Gerd, the doctor, and, of course, Goldberg, the cook, were revealed to the fans as well. Both of them seem to be much better in terms of nature when compared to Rodo, although they do have a job and that is to capture any and all intruders.',\n",
       " 'That is precisely why the Straw Hat Pirates decided to hide from them, and as soon as they passed, they decided to climb the bridge and go higher. Fans got to see quite a lot of the geography of Elbaf while all this was happening. Amid the giant rope bridge and the massive castle that fans got to see, there were absolutely giant wolves across the forest. It was around this time that Luffy felt the presence of an unusually strong individual, although at this point, it was unknown who this person truly was.',\n",
       " \"Luffy and Zoro were both ready to explore this source of energy, but of course, Sanji, being a capable leader, stepped in and stopped Zoro from doing just that. Sanji's reasoning behind this was that he would simply end up getting lost. This was completely justified, and at the same time, it also works as an interesting plot device, as it sets up Luffy alone with this source of power, and at the same time, puts Sanji and Zoro at the lead of the remaining part of the crew. Now, both of them are headed in different directions, although Luffy promised to meet them across the other end of the bridge. It will be interesting to see if that does end up happening, because Luffy has certainly run into an incredibly intriguing individual.\",\n",
       " \"Meanwhile, fans also got to see the other half of the Straw Hat Pirates in One Piece chapter 1130. This shouldn't come as a surprise to any fan, and was predicted by us here on Gamerant. The other half of the Strawhat Pirates is already in Elbaf, and this is simply because they have not found any clue about the missing members. Knowing that Luffy and the others are capable, they decided to go to Elbaf and wait for them there. While heading to the land of Elbaf itself, fans saw quite an interesting bit of information being revealed about the country. It was revealed to the fans that Elbaf has been somewhat tumultuous over the course of the last few years.\",\n",
       " 'In the quest for the legendary devil fruit, he killed his father, Harald! â€“ Giants',\n",
       " \"This was largely due to an individual known as the Accursed Prince. This individual, ever since he was born, continued to commit all sorts of crimes and, at the same time, cause issues wherever he went. His reputation was already incredibly bad. If that wasn't enough, he then decided to kill his own father, the king, and following that, consume a legendary devil fruit passed down the royal family. This legendary devil fruit was not revealed to the fans, but it is only a matter of time before it comes into play.\",\n",
       " 'Luffy could take on the legendary Loki in a battle in One Piece 1131. Loki could showcase an incredible devil fruit.',\n",
       " \"The Accursed Prince was then chained in Elbaf, and this was a task that required the strength of every single warrior on the island. This shouldn't be underestimated, because the Giants are the strongest race in the entire world, and the fact that it required every single one of them to actually capture the Accursed Prince goes to show how strong he truly is. The Giants believe that if the Accursed Prince is cut loose, he will most definitely cause the destruction of the world.\",\n",
       " ' Finally, in One Piece chapter 1130, it was revealed to the fans that the Accursed Prince was none other than Prince Loki, who was introduced in the Whole Cake Island Arc. The person who Luffy sensed while going up the bridge was also Loki, and in the final few pages, fans got a glorious look at this individual. Loki seems to be a mixture of Doflamingo, Katakuri, and Kaido, design-wise. He appears to be quite a delinquent and, at the same time, loves chaos. Loki believes himself to be the Sun God and the one who will destroy this world.',\n",
       " 'Meanwhile, Luffy seems to be quite intrigued by him, but, as things stand, he is not on his guard, which suggests that Luffy might not necessarily see him as an enemy, at least right now. But, the fact that both Luffy and Loki are the Sun Gods certainly does set up a confrontation between them, at least for now. While their relationship might be hostile at the beginning, it will likely be more friendly later down the line in Elbaf, and that is something that fans should keep an eye out for.',\n",
       " \" Loki certainly took away all the shine in the chapter, but fans also got to see the entire design of Elbaf, and it is safe to say that this country looks absolutely mesmerizing. Amid all the mountains, there is an absolutely massive tree, which fans know to be Yggdrasil, and along the midway of the tree, there is another level where the giant castle and the road bridge exist. This all connects to the level on the very top, which fans don't know much about at this point in time. Clearly, this is based on the concept similar to The Niflheim, the Midgard, and the Asgard from Norse mythology. Oda is always looking to incorporate similar ideas into Elbaf, and fans absolutely cannot wait to see what comes next.\",\n",
       " 'One Piece is available to read via Viz Media. The series can be read by the fans officially and for free on the Shonen Jump and the Manga Plus app. The release date for the next chapter of One Piece, One Piece 1131, is set to be November 11, 2024.',\n",
       " '',\n",
       " 'Your changes have been saved']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_text = []\n",
    "# for idx, p in enumerate(paragraphs[4:14]):\n",
    "for idx, p in enumerate(paragraphs):\n",
    "    print(idx, len(p), len(p.get_text())) # use enumerate to track line number visually\n",
    "    para_text.append(p.get_text())\n",
    "\n",
    "print(f'Number of Paragraphs:{len(para_text)}')\n",
    "para_text[4:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dd11309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Paragraphs: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to hold filtered text\n",
    "para_text = []\n",
    "\n",
    "# Define start and end markers for gamerant.com\n",
    "start_marker = \"You’ve reached your account maximum\"\n",
    "end_marker = \"One Piece is available to read via Viz Media.\"\n",
    "\n",
    "# Define start and end markers for screenrant.com\n",
    "# start_marker = \"You’ve reached your account maximum\"\n",
    "# end_marker = \"Created by Eiichiro Oda\"\n",
    "\n",
    "# Flags to track whether we're in the section we want\n",
    "in_section = False\n",
    "\n",
    "# Iterate through each paragraph\n",
    "for idx, p in enumerate(paragraphs):\n",
    "    text = p.get_text(strip=True)  # Extract and strip whitespace around text\n",
    "\n",
    "    # Start capturing paragraphs after the start_marker\n",
    "    if start_marker in text:\n",
    "        in_section = True\n",
    "        continue  # Skip the marker paragraph itself\n",
    "\n",
    "    # Stop capturing when we hit the end_marker\n",
    "    if end_marker in text:\n",
    "        break\n",
    "\n",
    "    # Append paragraph if within the desired section\n",
    "    if in_section and len(text) > 0:  # Example length filter\n",
    "        para_text.append(text)\n",
    "\n",
    "# Show results\n",
    "print(f'Number of Paragraphs: {len(para_text)}')\n",
    "for idx, text in enumerate(para_text):\n",
    "    print(f\"Paragraph {idx + 1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572a292",
   "metadata": {},
   "source": [
    "# NLP Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2e7e8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528571a9",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fe124d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# cv = CountVectorizer(stop_words='english')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# cv = CountVectorizer(stop_words='english', min_df=3) # ignore words that appear in only 'n' documents.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# cv = CountVectorizer(stop_words='english',max_df=0.5) # ignore words that don't appear in at least half of the documents\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m cv\u001b[38;5;241m.\u001b[39mget_feature_names_out()[:]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1334\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;124;03m        Fitted vectorizer.\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1383\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1375\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1380\u001b[0m             )\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1386\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1289\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1291\u001b[0m         )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "# cv = CountVectorizer(stop_words='english')\n",
    "# cv = CountVectorizer(stop_words='english', min_df=3) # ignore words that appear in only 'n' documents.\n",
    "# cv = CountVectorizer(stop_words='english',max_df=0.5) # ignore words that don't appear in at least half of the documents\n",
    "cv.fit(para_text)\n",
    "cv.get_feature_names_out()[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts Shape: (25, 488)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<25x488 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 781 stored elements in Compressed Sparse Row format>,\n",
       " None)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = cv.transform(para_text)\n",
    "counts, print(f'Counts Shape: {counts.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00144da6",
   "metadata": {},
   "source": [
    "### Counts Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (6, 3)\t1\n",
      "  (7, 2)\t1\n",
      "  (17, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "print(counts[:,:5]) # sparse matrix (row,col) coordinates with count value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e857c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.toarray()[:10,:22] # sparse matrix format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f64e1b",
   "metadata": {},
   "source": [
    "### Counts DateFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1130</th>\n",
       "      <th>1130one</th>\n",
       "      <th>2023</th>\n",
       "      <th>abilities</th>\n",
       "      <th>accidently</th>\n",
       "      <th>according</th>\n",
       "      <th>accursed</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>willing</th>\n",
       "      <th>with</th>\n",
       "      <th>within</th>\n",
       "      <th>won</th>\n",
       "      <th>world</th>\n",
       "      <th>worst</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1130  1130one  2023  abilities  accidently  according  accursed  act  \\\n",
       "4     0        0     0          0           0          1         1    2   \n",
       "5     0        0     0          0           0          0         0    0   \n",
       "6     0        0     0          1           0          0         0    0   \n",
       "7     0        0     1          0           0          0         0    0   \n",
       "8     0        0     0          0           0          0         0    0   \n",
       "9     0        0     0          0           0          0         0    0   \n",
       "\n",
       "   action  actually  ...  willing  with  within  won  world  worst  years  \\\n",
       "4       0         0  ...        0     1       1    0      0      0      0   \n",
       "5       0         0  ...        0     1       0    0      0      0      0   \n",
       "6       0         0  ...        0     1       0    0      1      0      0   \n",
       "7       1         0  ...        0     4       0    0      1      0      1   \n",
       "8       0         0  ...        0     0       0    0      0      0      0   \n",
       "9       0         0  ...        0     0       0    0      0      0      0   \n",
       "\n",
       "   yet  you  your  \n",
       "4    0    0     0  \n",
       "5    0    0     0  \n",
       "6    0    0     0  \n",
       "7    0    0     0  \n",
       "8    0    0     1  \n",
       "9    0    0     0  \n",
       "\n",
       "[6 rows x 488 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(counts.toarray(),columns=cv.get_feature_names_out())\n",
    "cv_df.iloc[4:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac761520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Total Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loki</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>his</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>as</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>luffy</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Term  Total Count\n",
       "0    the           53\n",
       "1     to           25\n",
       "2     of           24\n",
       "3    and           22\n",
       "4   loki           20\n",
       "5     is           19\n",
       "6    his           16\n",
       "7     in           15\n",
       "8     as           15\n",
       "9  luffy           14"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the counts across all documents for each term\n",
    "total_counts = cv_df.sum(axis=0)\n",
    "total_counts_df = total_counts.reset_index()\n",
    "total_counts_df.columns = ['Term', 'Total Count']\n",
    "total_counts_df.sort_values(by='Total Count', ascending=False).reset_index(drop=True).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec760e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paragraph  Word Count\n",
       "2           2         115\n",
       "4           4         105\n",
       "1           1         101\n",
       "7           7          97\n",
       "0           0          78\n",
       "5           5          60\n",
       "6           6          60\n",
       "16         16          41\n",
       "17         17          38\n",
       "15         15          37"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_word_count = cv_df.sum(axis=1)\n",
    "para_wc_df = para_word_count.reset_index()\n",
    "para_wc_df.columns = ['Paragraph', 'Word Count']\n",
    "para_wc_df.sort_values(by='Word Count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b77b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     25.000000\n",
       "mean      38.600000\n",
       "std       34.795833\n",
       "min        3.000000\n",
       "25%       14.000000\n",
       "50%       25.000000\n",
       "75%       60.000000\n",
       "max      115.000000\n",
       "Name: Word Count, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_wc_df['Word Count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999a5b9",
   "metadata": {},
   "source": [
    "### Find Total Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Words in Article:\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "tot_wc = para_wc_df['Word Count'].sum(axis=0)\n",
    "print(f'Total Number of Words in Article:\\n{tot_wc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a120fe4",
   "metadata": {},
   "source": [
    "### Estimating Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3425\n",
      "Estimated reading time from 3.9 to 4.8 minutes\n"
     ]
    }
   ],
   "source": [
    "# words per minute read time estimator:\n",
    "#upper/lower bound vector\n",
    "ublb = np.array([1/200, 1/250]) # conversation factor between 200 to 250 words per minute\n",
    "art = tot_wc * ublb\n",
    "art = art[::-1]\n",
    "print(art.mean())\n",
    "print(f'Estimated reading time from {round(art[0],1)} to {round(art[1],1)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b5228",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "TF: Term Frequency\n",
    "\n",
    "IDF: Inverse Term Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adf5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Columns: 375 entries, 1130 to years\n",
      "dtypes: float64(375)\n",
      "memory usage: 73.4 KB\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(stop_words='english')\n",
    "f = tv.fit_transform(para_text)\n",
    "tva = pd.DataFrame(f.toarray(),columns=tv.get_feature_names_out())\n",
    "tva.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loki       2.004649\n",
       "email      1.840183\n",
       "luffy      1.528530\n",
       "sent       1.479987\n",
       "saved      1.326531\n",
       "chapter    0.821103\n",
       "series     0.819336\n",
       "comment    0.748384\n",
       "changes    0.748384\n",
       "land       0.694053\n",
       "dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tva.sum(axis=0).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb34026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((375,), 3.5649493574615367, 2.0608719606852626)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.idf_.shape, tv.idf_.max(), tv.idf_.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84f2ff",
   "metadata": {},
   "source": [
    "# Estimating Read Times Experiment \n",
    "Take a random sample of length/complexity documents and time the users read time for each document. Model read time against length/complexity.\n",
    "\n",
    "Test for random repeat documents. How does a second reading within a certain time period effect read time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
